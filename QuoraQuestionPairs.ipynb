{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "4CJGryeoDM-i",
    "outputId": "96ea1d45-e427-4b51-a88c-55aee67772c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import collections\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import preprocessing, model_selection  \n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "98OT-W4VDM-p"
   },
   "outputs": [],
   "source": [
    "#load trianing data\n",
    "\n",
    "def load_data():\n",
    "    print(\"loading training data...\")\n",
    "    x_train, y_train = [], []\n",
    "    df_train = pd.read_csv(\"train.csv\", low_memory = False).dropna()\n",
    "    for index, row in df_train.iterrows():\n",
    "        s1, s2 = nltk.word_tokenize(row[\"question1\"]), nltk.word_tokenize(row[\"question2\"])\n",
    "        sen1, sen2 = [w.lower() for w in s1 if w.isalnum()], [w.lower() for w in s2 if w.isalnum()] #keep only alphanumeric words\n",
    "        x_train.append([sen1, sen2])\n",
    "        del s1, s2, sen1, sen2\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return x_train, list(df_train[\"is_duplicate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "z3VfRpGrDM-u",
    "outputId": "6cdcb7af-3ad2-473e-da7f-8fd097f9d953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "x_tokens, y_train = load_data()\n",
    "assert len(x_tokens)==len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9wxPZDzSDM-y",
    "outputId": "3be9250b-d359-49f7-a1ea-04ea0dff3352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india'], ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market']] 404287\n"
     ]
    }
   ],
   "source": [
    "print(x_tokens[0], len(x_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1ERLbTLDM-0"
   },
   "outputs": [],
   "source": [
    "# GloVe Encoding\n",
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "osYogIxyDM-4",
    "outputId": "742e8983-d073-4844-a403-ee620f622fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "encodings = loadGloveModel('glove.6B.300d.txt') #loading GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hkSPAiQRDM-8",
    "outputId": "9ddc91a7-efa3-46f9-de8a-89f80e06ec26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings['step'].shape #checking -> should be (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUNpbYEWDM_C"
   },
   "outputs": [],
   "source": [
    "def pair_encodings(data, encodings):\n",
    "    X, count = [], 0\n",
    "    for i,pair in enumerate(data):\n",
    "        v1, v2 = np.sum([encodings[w] for w in pair[0] if w in encodings], axis=0)/len(pair[0]), np.sum([encodings[w] for w in pair[1] if w in encodings], axis=0)/len(pair[1])\n",
    "        if v1.shape==(300,) and v2.shape==(300,):\n",
    "            vec = np.append(v1,v2).reshape(600,)\n",
    "            assert vec.shape == (600,)\n",
    "            X.append(vec)\n",
    "            del vec\n",
    "        else:\n",
    "            count+=1\n",
    "            print(pair, count)\n",
    "            del y_train[i]\n",
    "        del v1, v2\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "Lt_XfHrPDM_F",
    "outputId": "7cd0548b-f555-4021-e163-01e2dac635b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['why', 'is', 'cornell', 'endowment', 'the', 'lowest', 'in', 'the', 'ivy', 'league']] 1\n",
      "[[], ['why', 'should', 'one', 'not', 'work', 'at', 'google']] 2\n",
      "[['what', 'is', 'the', 'most', 'visited', 'tourist', 'attraction', 'in', 'africa'], ['उसपर']] 3\n",
      "[['how', 'could', 'i', 'solve', 'this'], []] 4\n",
      "[[], ['what', 'is', 'the', 'gmail', 'tech', 'support', 'help', 'phone', 'number']] 5\n",
      "[['is', 'there', 'anywhere', 'in', 'the', 'world', 'offering', 'pain', 'management', 'for', 'peripheral', 'neuropathy', 'as', 'opioids', 'haved', 'been', 'banned', 'in', 'us'], []] 6\n",
      "[['is', 'there', 'any', 'chances', 'for', 'hailstones', 'tomorrow'], ['parisflatlist']] 7\n",
      "[['since', 'childhood', 'why', 'are', 'we', 'taught', 'to', 'use', 'our', 'right', 'and', 'not', 'the', 'left', 'hand', 'for', 'writing', 'and', 'having', 'food'], ['aosdhiadsoihadso', 'dasodashdasoh']] 8\n",
      "[[], ['who', 'are', 'moses', 'noah', 'and', 'exodus']] 9\n",
      "[[], ['problem', 'of', 'solving', 'a', 'problem', 'is', 'not', 'a', 'problem', 'but', 'when', 'a', 'problem', 'solves', 'a', 'problem', 'without', 'any', 'problem', 'then', 'the', 'problem', 'is', 'not', 'at', 'all', 'a', 'problem', 'why']] 10\n",
      "[[], ['what', 'is', 'your', 'take', 'on', 'the', 'undercover', 'report', 'that', 'hints', 'that', 'indian', 'gov', 'plans', 'to', 'capture', 'kshatriya', 'caste', 'people', 'and', 'sends', 'them', 'to', 'border']] 11\n",
      "[['javac', 'javacpl', 'javaw'], ['what', 'is', 'new', 'in', 'jdk', '8']] 12\n",
      "[[], ['can', 'a', 'year', 'have', 'as', 'same', 'day']] 13\n",
      "[[], ['who', 'is', 'noah']] 14\n",
      "[[], ['time', 'is', 'some', 'one', 'explain', 'how', 'it', 'works']] 15\n",
      "[[], ['given', 'that', 'pacer', 'makes', 'money', 'from', 'usage', 'why', 'does', 'the', 'legal', 'profession', 'tolerate', 'its', 'absurd', 'awfulness']] 16\n",
      "[[], ['what', 'is', 'it', 'like', 'to', 'work', 'at', 'google']] 17\n",
      "[['test', 'your', 'iq', 'if', '5', '3', '28', '9', '1', '810', '8', '6', '214', '5', '4', '19', 'then', '7', '2', 'i', 'know', 'the', 'answer', 'can', 'somebody', 'find', 'a', 'real', 'complicated', 'way', 'to', 'answer', 'it'], []] 18\n",
      "[['which', 'in', 'the', 'best', 'bike', 'desert', 'storm', 'or', 'himalayan', 'i', 'm', 'gona', 'buy', 'in', 'next', '3', 'months'], []] 19\n",
      "[[], ['how', 'do', 'i', 'convince', 'my', 'friends', 'that', 'not', 'all', 'indians', 'are', 'cow', 'worshippers', 'and', 'not', 'all', 'of', 'them', 'text', 'every', 'woman', 'they', 'find', 'on', 'facebook']] 20\n",
      "[[], ['how', 'can', 'i', 'describe', 'quora', 'in', 'all', 'its', 'glory', 'to', 'friends']] 21\n",
      "[['तक', 'जगह', 'पर', 'एक'], ['why', 'are', 'all', 'expression', 'in', 'a', 'highly', 'more', 'so', 'than', 'genes']] 22\n",
      "[[], ['what', 'do', 'i', 'do', 'with', 'this', 'guy']] 23\n",
      "[['wunderlist', 'todoist'], ['which', 'one', 'did', 'you', 'choose', 'wunderlist', 'or', 'todoist']] 24\n",
      "[[], ['brain', 'teasers', 'what', 'is', 'the', 'significance', 'of', 'this', 'series', '0', '6', '1', '2', '2', '5', '3', '5', '4', '4', '5', '5', '6', '6', '7', '3', '8', '7', '9', '6']] 25\n",
      "[['seomoz', 'seoprofiler'], ['why', 'does', 'seoprofiler', 'not', 'find', 'backlinks', 'to', 'my', 'site']] 26\n",
      "[['how', 'do', 'i', 'solve', 'this'], []] 27\n",
      "[[], ['what', 'is', 'cisco', 'router', 'technical', 'support', 'phone', 'number']] 28\n",
      "(404259, 600)\n"
     ]
    }
   ],
   "source": [
    "x_train = pair_encodings(x_tokens, encodings)\n",
    "print(x_train.shape)\n",
    "del x_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "olqs5e6cDM_N",
    "outputId": "2568d718-ead1-4cea-8f34-0804141b2677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404259, 600) (404259,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, np.array(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgGe79uvWHXr"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(x_train, np.array(y_train), test_size=0.025, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3AYYoM-0Xp8F",
    "outputId": "dcc1166f-1b5d-4609-cfb3-523299715ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394152, 600) (10107, 600)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2264
    },
    "colab_type": "code",
    "id": "Fj2LcUHkmmGh",
    "outputId": "73670279-f50a-44be-924d-47756a3f58ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 394152 samples, validate on 10107 samples\n",
      "Epoch 1/60\n",
      "394152/394152 [==============================] - 47s 119us/step - loss: 0.5645 - acc: 0.7064 - val_loss: 0.5067 - val_acc: 0.7377\n",
      "Epoch 2/60\n",
      "394152/394152 [==============================] - 45s 115us/step - loss: 0.5194 - acc: 0.7344 - val_loss: 0.4879 - val_acc: 0.7563\n",
      "Epoch 3/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.5018 - acc: 0.7438 - val_loss: 0.4860 - val_acc: 0.7537\n",
      "Epoch 4/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4916 - acc: 0.7506 - val_loss: 0.4671 - val_acc: 0.7655\n",
      "Epoch 5/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4829 - acc: 0.7564 - val_loss: 0.4677 - val_acc: 0.7645\n",
      "Epoch 6/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4763 - acc: 0.7607 - val_loss: 0.4559 - val_acc: 0.7725\n",
      "Epoch 7/60\n",
      "394152/394152 [==============================] - 45s 115us/step - loss: 0.4700 - acc: 0.7648 - val_loss: 0.4535 - val_acc: 0.7786\n",
      "Epoch 8/60\n",
      "394152/394152 [==============================] - 44s 113us/step - loss: 0.4643 - acc: 0.7692 - val_loss: 0.4514 - val_acc: 0.7785\n",
      "Epoch 9/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4603 - acc: 0.7709 - val_loss: 0.4503 - val_acc: 0.7850\n",
      "Epoch 10/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4565 - acc: 0.7739 - val_loss: 0.4401 - val_acc: 0.7853\n",
      "Epoch 11/60\n",
      "394152/394152 [==============================] - 46s 117us/step - loss: 0.4523 - acc: 0.7765 - val_loss: 0.4422 - val_acc: 0.7800\n",
      "Epoch 12/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4493 - acc: 0.7788 - val_loss: 0.4505 - val_acc: 0.7794\n",
      "Epoch 13/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.4460 - acc: 0.7805 - val_loss: 0.4399 - val_acc: 0.7855\n",
      "Epoch 14/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4426 - acc: 0.7826 - val_loss: 0.4355 - val_acc: 0.7903\n",
      "Epoch 15/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.4399 - acc: 0.7845 - val_loss: 0.4402 - val_acc: 0.7872\n",
      "Epoch 16/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4386 - acc: 0.7856 - val_loss: 0.4370 - val_acc: 0.7862\n",
      "Epoch 17/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.4346 - acc: 0.7878 - val_loss: 0.4322 - val_acc: 0.7916\n",
      "Epoch 18/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4329 - acc: 0.7898 - val_loss: 0.4325 - val_acc: 0.7935\n",
      "Epoch 19/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.4308 - acc: 0.7901 - val_loss: 0.4347 - val_acc: 0.7934\n",
      "Epoch 20/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4280 - acc: 0.7918 - val_loss: 0.4276 - val_acc: 0.7944\n",
      "Epoch 21/60\n",
      "394152/394152 [==============================] - 43s 110us/step - loss: 0.4257 - acc: 0.7936 - val_loss: 0.4316 - val_acc: 0.7934\n",
      "Epoch 22/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4247 - acc: 0.7944 - val_loss: 0.4258 - val_acc: 0.7922\n",
      "Epoch 23/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.4223 - acc: 0.7957 - val_loss: 0.4262 - val_acc: 0.7915\n",
      "Epoch 24/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.4208 - acc: 0.7971 - val_loss: 0.4253 - val_acc: 0.7967\n",
      "Epoch 25/60\n",
      "394152/394152 [==============================] - 45s 114us/step - loss: 0.4183 - acc: 0.7984 - val_loss: 0.4270 - val_acc: 0.7959\n",
      "Epoch 26/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.4166 - acc: 0.7993 - val_loss: 0.4247 - val_acc: 0.8009\n",
      "Epoch 27/60\n",
      "394152/394152 [==============================] - 46s 116us/step - loss: 0.4158 - acc: 0.7996 - val_loss: 0.4276 - val_acc: 0.7954\n",
      "Epoch 28/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.4143 - acc: 0.8009 - val_loss: 0.4340 - val_acc: 0.7914\n",
      "Epoch 29/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4122 - acc: 0.8017 - val_loss: 0.4236 - val_acc: 0.8006\n",
      "Epoch 30/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.4105 - acc: 0.8033 - val_loss: 0.4238 - val_acc: 0.7989\n",
      "Epoch 31/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4094 - acc: 0.8035 - val_loss: 0.4228 - val_acc: 0.7994\n",
      "Epoch 32/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.4069 - acc: 0.8056 - val_loss: 0.4248 - val_acc: 0.7966\n",
      "Epoch 33/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4059 - acc: 0.8060 - val_loss: 0.4218 - val_acc: 0.8004\n",
      "Epoch 34/60\n",
      "394152/394152 [==============================] - 45s 115us/step - loss: 0.4057 - acc: 0.8060 - val_loss: 0.4227 - val_acc: 0.7973\n",
      "Epoch 35/60\n",
      "394152/394152 [==============================] - 43s 110us/step - loss: 0.4044 - acc: 0.8070 - val_loss: 0.4206 - val_acc: 0.7971\n",
      "Epoch 36/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4029 - acc: 0.8084 - val_loss: 0.4231 - val_acc: 0.7995\n",
      "Epoch 37/60\n",
      "394152/394152 [==============================] - 43s 110us/step - loss: 0.4007 - acc: 0.8092 - val_loss: 0.4204 - val_acc: 0.8002\n",
      "Epoch 38/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.4007 - acc: 0.8090 - val_loss: 0.4268 - val_acc: 0.7997\n",
      "Epoch 39/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.3985 - acc: 0.8100 - val_loss: 0.4186 - val_acc: 0.8008\n",
      "Epoch 40/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.3985 - acc: 0.8105 - val_loss: 0.4177 - val_acc: 0.7980\n",
      "Epoch 41/60\n",
      "394152/394152 [==============================] - 45s 113us/step - loss: 0.3981 - acc: 0.8108 - val_loss: 0.4198 - val_acc: 0.8009\n",
      "Epoch 42/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.3969 - acc: 0.8107 - val_loss: 0.4206 - val_acc: 0.8016\n",
      "Epoch 43/60\n",
      "394152/394152 [==============================] - 44s 110us/step - loss: 0.3942 - acc: 0.8124 - val_loss: 0.4246 - val_acc: 0.7980\n",
      "Epoch 44/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.3938 - acc: 0.8127 - val_loss: 0.4229 - val_acc: 0.8037\n",
      "Epoch 45/60\n",
      "394152/394152 [==============================] - 43s 110us/step - loss: 0.3932 - acc: 0.8137 - val_loss: 0.4222 - val_acc: 0.7997\n",
      "Epoch 46/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.3928 - acc: 0.8139 - val_loss: 0.4311 - val_acc: 0.7998\n",
      "Epoch 47/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.3917 - acc: 0.8144 - val_loss: 0.4293 - val_acc: 0.8008\n",
      "Epoch 48/60\n",
      "394152/394152 [==============================] - 43s 110us/step - loss: 0.3904 - acc: 0.8155 - val_loss: 0.4221 - val_acc: 0.7992\n",
      "Epoch 49/60\n",
      "394152/394152 [==============================] - 45s 113us/step - loss: 0.3892 - acc: 0.8156 - val_loss: 0.4202 - val_acc: 0.8010\n",
      "Epoch 50/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.3896 - acc: 0.8156 - val_loss: 0.4220 - val_acc: 0.8035\n",
      "Epoch 51/60\n",
      "394152/394152 [==============================] - 44s 111us/step - loss: 0.3877 - acc: 0.8161 - val_loss: 0.4215 - val_acc: 0.8007\n",
      "Epoch 52/60\n",
      "394152/394152 [==============================] - 42s 107us/step - loss: 0.3877 - acc: 0.8168 - val_loss: 0.4218 - val_acc: 0.8025\n",
      "Epoch 53/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.3860 - acc: 0.8176 - val_loss: 0.4168 - val_acc: 0.8042\n",
      "Epoch 54/60\n",
      "394152/394152 [==============================] - 42s 107us/step - loss: 0.3851 - acc: 0.8182 - val_loss: 0.4224 - val_acc: 0.7996\n",
      "Epoch 55/60\n",
      "394152/394152 [==============================] - 44s 112us/step - loss: 0.3865 - acc: 0.8178 - val_loss: 0.4240 - val_acc: 0.8006\n",
      "Epoch 56/60\n",
      "394152/394152 [==============================] - 42s 106us/step - loss: 0.3838 - acc: 0.8190 - val_loss: 0.4216 - val_acc: 0.8034\n",
      "Epoch 57/60\n",
      "394152/394152 [==============================] - 43s 109us/step - loss: 0.3829 - acc: 0.8192 - val_loss: 0.4215 - val_acc: 0.8018\n",
      "Epoch 58/60\n",
      "394152/394152 [==============================] - 43s 108us/step - loss: 0.3823 - acc: 0.8195 - val_loss: 0.4223 - val_acc: 0.8025\n",
      "Epoch 59/60\n",
      "394152/394152 [==============================] - 42s 107us/step - loss: 0.3825 - acc: 0.8200 - val_loss: 0.4268 - val_acc: 0.8049\n",
      "Epoch 60/60\n",
      "394152/394152 [==============================] - 44s 110us/step - loss: 0.3808 - acc: 0.8200 - val_loss: 0.4247 - val_acc: 0.8047\n",
      "10107/10107 [==============================] - 0s 14us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, kernel_initializer='normal', input_dim=600, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, np.array(y_train), epochs=60, batch_size=64, validation_data=(x_val, y_val))\n",
    "score = model.evaluate(x_val, y_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEw8KVUVmoPV"
   },
   "outputs": [],
   "source": [
    "del x_train, x_val, y_train, y_val #freeing RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1907
    },
    "colab_type": "code",
    "id": "70fDxko9hR3X",
    "outputId": "08882f3f-6c48-43f8-a587-3804cb30d09b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47707 1\n",
      "56929 2\n",
      "89963 3\n",
      "94646 4\n",
      "111392 5\n",
      "121810 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144334 7\n",
      "197732 8\n",
      "294600 9\n",
      "316017 10\n",
      "320933 11\n",
      "364725 12\n",
      "379205 has a null object!\n",
      "379205 13\n",
      "395482 14\n",
      "469325 15\n",
      "498004 16\n",
      "498781 17\n",
      "507834 18\n",
      "575003 19\n",
      "631690 20\n",
      "647844 21\n",
      "671066 22\n",
      "672455 23\n",
      "681754 24\n",
      "684886 25\n",
      "714289 26\n",
      "726779 27\n",
      "730790 28\n",
      "788917 29\n",
      "792864 30\n",
      "805015 31\n",
      "807779 32\n",
      "817520 has a null object!\n",
      "817520 33\n",
      "856433 34\n",
      "884278 35\n",
      "902143 36\n",
      "913286 37\n",
      "923320 38\n",
      "943911 has a null object!\n",
      "943911 39\n",
      "948749 40\n",
      "963864 41\n",
      "976382 42\n",
      "1021275 43\n",
      "1046690 has a null object!\n",
      "1046690 44\n",
      "1049034 45\n",
      "1070499 46\n",
      "1114263 47\n",
      "1114544 48\n",
      "1221596 49\n",
      "1250219 50\n",
      "1266178 51\n",
      "1270024 has a null object!\n",
      "1270024 52\n",
      "1312352 53\n",
      "1316479 54\n",
      "1341861 55\n",
      "1355809 56\n",
      "1404324 57\n",
      "1407596 58\n",
      "1432959 59\n",
      "1436078 60\n",
      "1461432 has a null object!\n",
      "1461432 61\n",
      "1567104 62\n",
      "1619208 63\n",
      "1635393 64\n",
      "1697898 65\n",
      "1722030 66\n",
      "1728010 67\n",
      "1735488 68\n",
      "1768203 69\n",
      "1774201 70\n",
      "1827360 71\n",
      "1836463 72\n",
      "1894751 73\n",
      "1922872 74\n",
      "1959010 75\n",
      "1967420 76\n",
      "1977114 77\n",
      "1979732 78\n",
      "2004705 79\n",
      "2009885 80\n",
      "2037090 81\n",
      "2049895 82\n",
      "2051949 83\n",
      "2114530 84\n",
      "2115520 85\n",
      "2134489 86\n",
      "2164990 87\n",
      "2170816 88\n",
      "2185124 89\n",
      "2191968 90\n",
      "2214117 91\n",
      "2215517 92\n",
      "2218501 93\n",
      "2222892 94\n",
      "2235682 95\n",
      "2239731 96\n",
      "2251201 97\n",
      "2272879 98\n",
      "2275540 99\n",
      "2290763 100\n",
      "2333701 101\n"
     ]
    }
   ],
   "source": [
    "#Writing test results to CSV\n",
    "\n",
    "with open('test_results.csv', mode='w') as file:\n",
    "  writer = csv.writer(file, delimiter=\",\")\n",
    "  writer.writerow(['test_id','is_duplicate'])\n",
    "  df_test = pd.read_csv(\"test.csv\", low_memory = False)\n",
    "  x_test, no_array, count = [], [], 0\n",
    "  for index,row in df_test.iterrows():\n",
    "    if pd.isnull(row[\"question1\"])==False:\n",
    "      s1 = nltk.word_tokenize(row[\"question1\"])\n",
    "      sen1 = [w.lower() for w in s1 if w.isalnum()]; del s1  #keep only alphanumeric words\n",
    "      v1 = [encodings[w] for w in sen1 if w in encodings]; del sen1\n",
    "      vec1 = np.sum(v1, axis=0)/len(v1); del v1\n",
    "    else:\n",
    "      print(index, \"has a null object!\")\n",
    "      vec1 = np.array([])\n",
    "    if pd.isnull(row[\"question2\"])==False:\n",
    "      s2 = nltk.word_tokenize(row[\"question2\"])\n",
    "      sen2 = [w.lower() for w in s2 if w.isalnum()]; del s2  #keep only alphanumeric words\n",
    "      v2 = [encodings[w] for w in sen2 if w in encodings]; del sen2\n",
    "      vec2 = np.sum(v2, axis=0)/len(v2); del v2\n",
    "    else:\n",
    "      print(index, \"has a null object!\")\n",
    "      vec2 = np.array([])\n",
    "    if vec1.shape==(300,) and vec2.shape==(300,):\n",
    "      vec = np.append(vec1,vec2).reshape(600,); del vec1, vec2\n",
    "      assert vec.shape == (600,)\n",
    "      score = model.predict(vec.reshape(1,600))\n",
    "      pred = 0 if score <=0.5 else 1\n",
    "      #print(pred)\n",
    "      writer.writerow([index,pred])\n",
    "      del vec\n",
    "    else:\n",
    "      writer.writerow([index,0])\n",
    "      count+=1\n",
    "      print(index, count)\n",
    "\n",
    "  \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmluovzApc5i"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_results.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "c4cjwRArPy2l",
    "outputId": "1ff5dfc1-6379-451d-fb7f-eb4f996674d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "2345791  2345791             0\n",
       "2345792  2345792             0\n",
       "2345793  2345793             0\n",
       "2345794  2345794             1\n",
       "2345795  2345795             0"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qnx-4HsoP0bB"
   },
   "outputs": [],
   "source": [
    "df1 = df[df[\"is_duplicate\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5sefNeMsQJOf",
    "outputId": "7a4a14e5-5145-4c98-9496-6f1b57982002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2b-IeETrQJ2m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QuoraQuestionPairs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
